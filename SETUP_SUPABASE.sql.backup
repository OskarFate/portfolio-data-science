-- ========================================
-- DESACTIVAR ROW LEVEL SECURITY (RLS)
-- ========================================
-- Ejecuta estos comandos en el SQL Editor de Supabase
-- https://supabase.com/dashboard/project/bajkdvhooousgtahuslp/sql

-- Desactivar RLS en todas las tablas
ALTER TABLE settings DISABLE ROW LEVEL SECURITY;
ALTER TABLE skills DISABLE ROW LEVEL SECURITY;
ALTER TABLE projects DISABLE ROW LEVEL SECURITY;
ALTER TABLE posts DISABLE ROW LEVEL SECURITY;
ALTER TABLE journey_stages DISABLE ROW LEVEL SECURITY;
ALTER TABLE journey_locations DISABLE ROW LEVEL SECURITY;
ALTER TABLE journey_philosophy DISABLE ROW LEVEL SECURITY;

-- ========================================
-- ACTUALIZAR ESTRUCTURA DE POSTS
-- ========================================
-- Agregar columnas necesarias para el blog del roadmap

DO $$ 
BEGIN
    -- Agregar column featured si no existe
    IF NOT EXISTS (SELECT 1 FROM information_schema.columns 
                   WHERE table_name='posts' AND column_name='featured') THEN
        ALTER TABLE posts ADD COLUMN featured BOOLEAN DEFAULT false;
    END IF;
    
    -- Agregar column week_number si no existe
    IF NOT EXISTS (SELECT 1 FROM information_schema.columns 
                   WHERE table_name='posts' AND column_name='week_number') THEN
        ALTER TABLE posts ADD COLUMN week_number INTEGER;
    END IF;
    
    -- Agregar column technologies si no existe
    IF NOT EXISTS (SELECT 1 FROM information_schema.columns 
                   WHERE table_name='posts' AND column_name='technologies') THEN
        ALTER TABLE posts ADD COLUMN technologies TEXT[];
    END IF;
END $$;

-- ========================================
-- INSERTAR DATOS DIRECTAMENTE
-- ========================================

-- 1. LIMPIAR DATOS EXISTENTES
DELETE FROM skills;
DELETE FROM journey_stages;
DELETE FROM journey_locations;
DELETE FROM journey_philosophy;
DELETE FROM posts;

-- 2. INSERTAR 18 SKILLS (Stack completo del roadmap de 104 semanas)
INSERT INTO skills (name, category, level, description) VALUES
-- Lenguajes de Programaci√≥n (3)
('Python', 'Lenguajes de Programaci√≥n', 'Intermedio', 'pandas, numpy, matplotlib, seaborn, scikit-learn'),
('SQL', 'Lenguajes de Programaci√≥n', 'Intermedio', 'Consultas anal√≠ticas, JOINs, CTEs, Window functions, optimizaci√≥n'),
('R', 'Lenguajes de Programaci√≥n', 'B√°sico', 'ggplot2, dplyr, tidyr, an√°lisis estad√≠stico'),

-- An√°lisis & Visualizaci√≥n (3)
('Power BI', 'An√°lisis & Visualizaci√≥n', 'Intermedio', 'Dashboards interactivos, DAX, modelado de datos, Power Query'),
('Tableau', 'An√°lisis & Visualizaci√≥n', 'B√°sico', 'Visualizaciones y storytelling con datos'),
('Excel', 'An√°lisis & Visualizaci√≥n', 'Avanzado', 'Tablas din√°micas, Power Query, VBA, an√°lisis avanzado'),

-- Ingenier√≠a de Datos (3)
('dbt', 'Ingenier√≠a de Datos', 'B√°sico', 'Transformaci√≥n de datos, modelado dimensional, tests'),
('Apache Airflow', 'Ingenier√≠a de Datos', 'B√°sico', 'Orquestaci√≥n de pipelines, DAGs, scheduling'),
('Apache Spark', 'Ingenier√≠a de Datos', 'B√°sico', 'Procesamiento distribuido, PySpark, big data'),

-- Cloud & Infraestructura (3)
('Google Cloud Platform', 'Cloud & Infraestructura', 'B√°sico', 'BigQuery, Cloud Storage, Vertex AI, Composer'),
('Docker', 'Cloud & Infraestructura', 'B√°sico', 'Contenedores, Dockerfile, docker-compose, deployment'),
('Git & GitHub', 'Cloud & Infraestructura', 'Intermedio', 'Control de versiones, colaboraci√≥n, CI/CD, GitHub Actions'),

-- Machine Learning & IA (3)
('Scikit-learn', 'Machine Learning & IA', 'B√°sico', 'Algoritmos supervisados, no supervisados, feature engineering'),
('LangChain', 'Machine Learning & IA', 'B√°sico', 'RAG, agentes inteligentes, LLMs, embeddings'),
('TensorFlow/PyTorch', 'Machine Learning & IA', 'B√°sico', 'Deep Learning, redes neuronales, computer vision'),

-- Business & Estrategia (3)
('An√°lisis de KPIs', 'Business & Estrategia', 'Intermedio', 'Definici√≥n de m√©tricas, dashboards ejecutivos, OKRs'),
('Data Storytelling', 'Business & Estrategia', 'Intermedio', 'Comunicaci√≥n de insights, presentaciones ejecutivas'),
('A/B Testing', 'Business & Estrategia', 'B√°sico', 'Experimentaci√≥n, an√°lisis estad√≠stico, hip√≥tesis de negocio');

-- 3. INSERTAR 5 ETAPAS DE VIDA
INSERT INTO journey_stages (emoji, title, description, order_index) VALUES
('üìö', 'Etapa 1 ‚Äî Formaci√≥n y Fundamentos', 'Construyendo bases s√≥lidas en Python, SQL, Power BI y an√°lisis de datos. Esta etapa se enfoca en dominar los fundamentos t√©cnicos a trav√©s de cursos, proyectos pr√°cticos y documentaci√≥n constante. El objetivo es crear un portfolio robusto que demuestre capacidad t√©cnica real, no solo certificados. Cada proyecto se documenta en GitHub y se comparte en LinkedIn para construir presencia profesional desde el inicio.', 0),
('ÔøΩ', 'Etapa 2 ‚Äî Primeros Proyectos Reales', 'Aplicaci√≥n pr√°ctica de habilidades en proyectos reales de an√°lisis de negocio. Dashboards ejecutivos con Power BI, an√°lisis exploratorio de datos con Python, y primeros modelos predictivos con machine learning. Esta etapa marca la transici√≥n de estudiante a profesional: cada proyecto resuelve problemas reales, genera valor medible y se presenta con storytelling efectivo. El portafolio evoluciona de ejercicios acad√©micos a casos de negocio documentados.', 1),
('üöÄ', 'Etapa 3 ‚Äî Expansi√≥n Global', 'Desarrollo de habilidades avanzadas: Machine Learning en producci√≥n, Cloud Engineering con GCP/AWS, automatizaci√≥n de pipelines con Airflow y dbt. Esta etapa implica dominar el stack completo de un Data Scientist senior: desde la ingesta de datos hasta el deployment de modelos. Se busca trabajar en proyectos internacionales, colaborar con equipos distribuidos y construir soluciones escalables que impacten a miles de usuarios.', 2),
('ÔøΩ', 'Etapa 4 ‚Äî Trabajo Remoto Internacional', 'Libertad geogr√°fica total mientras se trabaja para empresas globales. Esta etapa combina expertise t√©cnico con autonom√≠a profesional: elegir proyectos de alto impacto, trabajar con tecnolog√≠as de punta y mantener balance entre carrera y calidad de vida. El objetivo es posicionarse como especialista confiable en el mercado internacional, capaz de entregar valor desde cualquier ubicaci√≥n del mundo.', 3),
('‚≠ê', 'Etapa 5 ‚Äî Autonom√≠a Profesional', 'Trabajar por elecci√≥n estrat√©gica, no por necesidad econ√≥mica. Esta etapa representa la consolidaci√≥n de a√±os de experiencia: seleccionar proyectos que generen impacto real, colaborar con equipos de √©lite y tener la flexibilidad de explorar nuevas tecnolog√≠as. El enfoque est√° en proyectos de alto impacto que resuelvan problemas complejos, mentor√≠a a otros profesionales y contribuci√≥n a la comunidad t√©cnica global.', 4);

-- 4. INSERTAR 4 UBICACIONES
INSERT INTO journey_locations (country, flag, subtitle, city, description, highlights, order_index) VALUES
('Chile', 'üá®üá±', 'El Punto de Partida', 'Concepci√≥n', 'Base de operaciones. Desarrollo de carrera, proyectos y networking local.', ARRAY['Portfolio robusto', 'Ingl√©s avanzado', 'Experiencia pr√°ctica', 'Capital inicial'], 0),
('Australia', 'üá¶üá∫', 'Estabilidad y Crecimiento', 'Melbourne', 'Econom√≠a s√≥lida, meritocracia, calidad de vida. Hub tech en crecimiento.', ARRAY['Visa de trabajo calificado', 'Salarios competitivos', 'Networking internacional', 'Path a residencia'], 1),
('Singapur', 'üá∏üá¨', 'Hub Tecnol√≥gico Global', 'Central District', 'Centro financiero y tecnol√≥gico de Asia. Eficiencia, orden y oportunidades.', ARRAY['Impuestos bajos', 'Conexi√≥n Asia-Pac√≠fico', 'Calidad de vida premium', 'Comunidad tech'], 2),
('Europa', 'üá™üá∫', 'Exploraci√≥n Temporal', 'Berl√≠n / √Åmsterdam / Lisboa', 'Temporadas de trabajo remoto, networking europeo y experiencias culturales.', ARRAY['Escena tech vibrante', 'Visa de n√≥mada digital', 'Arte y cultura', 'Conexiones globales'], 3);

-- 5. INSERTAR FILOSOF√çA
INSERT INTO journey_philosophy (title, quote, verses, closing, final_thought) VALUES
('üïäÔ∏è Filosof√≠a de Ruta', 
 'No busco la vida f√°cil. Busco la vida correcta.',
 ARRAY['Chile me dio las bases.', 'Australia me dar√° estabilidad.', 'Singapur ser√° mi hub global.', 'Europa me dar√° experiencias.'],
 'Cada ubicaci√≥n es una decisi√≥n estrat√©gica.',
 'Mi ruta sigue mi visi√≥n, no las expectativas de otros.');

-- 6. INSERTAR POSTS DE EJEMPLO (Semanas del Roadmap)
-- Estos posts documentan el progreso semanal del roadmap de 104 semanas

-- Semana 1: Fundamentos Python
INSERT INTO posts (title, slug, excerpt, content, published, featured, week_number, technologies, reading_time) VALUES
(
  'üìä Semana 1: Fundamentos de Python para Data Science',
  'semana-1-fundamentos-python',
  'Primera semana del roadmap de 104 semanas. Aprend√≠ los fundamentos de Python: variables, tipos de datos, estructuras de control y funciones b√°sicas.',
  E'# üìä Semana 1: Fundamentos de Python para Data Science\n\n## üéØ Objetivo de la Semana\nEstablecer las bases s√≥lidas en Python, el lenguaje principal para ciencia de datos.\n\n## üìö Lo que Aprend√≠\n\n### 1. Variables y Tipos de Datos\n```python\n# Tipos b√°sicos\nnombre = "Data Scientist"\nedad = 25\naltura = 1.75\nes_estudiante = True\n```\n\n### 2. Estructuras de Control\n- Condicionales (if/elif/else)\n- Loops (for, while)\n- List comprehensions\n\n### 3. Funciones\n```python\ndef calcular_promedio(numeros):\n    return sum(numeros) / len(numeros)\n\nnotas = [85, 90, 78, 92]\npromedio = calcular_promedio(notas)\nprint(f"Promedio: {promedio}")\n```\n\n## üí° Highlights\n- ‚úÖ Complet√© 50 ejercicios en HackerRank\n- ‚úÖ Entend√≠ la diferencia entre listas y tuplas\n- ‚úÖ Aprend√≠ a usar f-strings para formateo\n\n## üöß Desaf√≠os\n- Las list comprehensions fueron confusas al principio\n- Debugging tom√≥ m√°s tiempo del esperado\n\n## üéØ Pr√≥xima Semana\n- Comenzar con NumPy y arrays\n- Aprender manipulaci√≥n de datos b√°sica\n- Crear mi primer mini-proyecto',
  true,
  true,
  1,
  ARRAY['Python', 'Fundamentos'],
  5
),
(
  'üî¢ Semana 2: NumPy y Manipulaci√≥n de Arrays',
  'semana-2-numpy-arrays',
  'Segunda semana enfocada en NumPy, la biblioteca fundamental para computaci√≥n num√©rica en Python. Arrays, operaciones vectorizadas y √°lgebra lineal b√°sica.',
  E'# üî¢ Semana 2: NumPy y Manipulaci√≥n de Arrays\n\n## üéØ Objetivo\nDominar NumPy para operaciones num√©ricas eficientes.\n\n## üìö Contenido\n\n### Arrays en NumPy\n```python\nimport numpy as np\n\n# Crear arrays\narr = np.array([1, 2, 3, 4, 5])\nmatriz = np.array([[1, 2], [3, 4]])\n\n# Operaciones vectorizadas\narr * 2  # M√°s r√°pido que loops\n```\n\n### Indexing y Slicing\n```python\n# Slicing avanzado\narr[1:4]  # [2, 3, 4]\nmatriz[:, 1]  # Segunda columna\n```\n\n### Funciones √ötiles\n- `np.mean()`, `np.std()`, `np.sum()`\n- `np.reshape()`, `np.transpose()`\n- Broadcasting de arrays\n\n## üí° Key Learnings\n- ‚úÖ NumPy es 100x m√°s r√°pido que listas Python puras\n- ‚úÖ Broadcasting evita loops expl√≠citos\n- ‚úÖ Arrays son la base de pandas y scikit-learn\n\n## üìä Proyecto: An√°lisis de Ventas\nCre√© un script que analiza datos de ventas usando NumPy:\n- Calcul√© promedios y desviaciones est√°ndar\n- Identifiqu√© outliers usando percentiles\n- Visualic√© resultados con matplotlib b√°sico\n\n## üéØ Pr√≥xima Semana\nComenzar con Pandas para an√°lisis de datos tabulares',
  true,
  false,
  2,
  ARRAY['Python', 'NumPy', 'Data Analysis'],
  8
),
(
  'üìä Semana 3: Pandas - El Poder de los DataFrames',
  'semana-3-pandas-dataframes',
  'Tercera semana dedicada a Pandas, la biblioteca m√°s importante para an√°lisis de datos. DataFrames, limpieza de datos y operaciones de agregaci√≥n.',
  E'# üìä Semana 3: Pandas - El Poder de los DataFrames\n\n## üéØ Objetivo\nAprender Pandas para manipulaci√≥n y an√°lisis de datos tabulares.\n\n## üìö Fundamentos\n\n### Crear DataFrames\n```python\nimport pandas as pd\n\n# Desde diccionario\ndata = {\n    "nombre": ["Ana", "Luis", "Mar√≠a"],\n    "edad": [25, 30, 28],\n    "salario": [50000, 60000, 55000]\n}\ndf = pd.DataFrame(data)\n```\n\n### Operaciones Esenciales\n```python\n# Exploraci√≥n\ndf.head()\ndf.info()\ndf.describe()\n\n# Filtrado\ndf[df["edad"] > 25]\n\n# Agregaciones\ndf.groupby("ciudad")["ventas"].mean()\n```\n\n### Limpieza de Datos\n- Manejo de valores nulos con `fillna()` y `dropna()`\n- Conversi√≥n de tipos con `astype()`\n- Eliminaci√≥n de duplicados con `drop_duplicates()`\n\n## üí° Highlights\n- ‚úÖ Pandas hace SQL-like queries en Python\n- ‚úÖ Method chaining hace c√≥digo m√°s legible\n- ‚úÖ `groupby()` es incre√≠blemente poderoso\n\n## üìä Proyecto: Dashboard de Ventas\nAnalic√© dataset de ventas de e-commerce:\n- Limpi√© 10,000 registros con datos faltantes\n- Calcul√© m√©tricas por categor√≠a y regi√≥n\n- Identifiqu√© top 10 productos m√°s vendidos\n- Export√© resultados a CSV y Excel\n\n## üöß Desaf√≠os\n- Entender `apply()` vs `map()` vs `applymap()`\n- Memory management con datasets grandes\n\n## üéØ Pr√≥xima Semana\nVisualizaci√≥n de datos con Matplotlib y Seaborn',
  true,
  true,
  3,
  ARRAY['Python', 'Pandas', 'Data Cleaning'],
  10
);

-- 7. ACTUALIZAR INFORMACI√ìN PERSONAL
-- Portfolio de Oskar Pardo Salazar

UPDATE settings SET
  name = 'Oskar Pardo Salazar',
  title = 'Data Scientist & Business Analyst',
  email = 'contacto@oskarpardo.dev',
  phone = '+56921892848',
  location = 'Concepci√≥n, Chile',
  bio = E'Transformando datos en decisiones estrat√©gicas.\n\nRoadmap de 104 semanas: Python, SQL, Machine Learning y Cloud Engineering.',
  github = 'https://github.com/OskarFate',
  linkedin = 'https://www.linkedin.com/in/oskarpardo/',
  twitter = '',
  roadmap_progress = 0
WHERE id = (SELECT id FROM settings LIMIT 1);

-- 8. VERIFICAR TODAS LAS TABLAS
SELECT 'SKILLS' as tabla, COUNT(*) as total FROM skills
UNION ALL
SELECT 'JOURNEY_STAGES', COUNT(*) FROM journey_stages
UNION ALL
SELECT 'JOURNEY_LOCATIONS', COUNT(*) FROM journey_locations
UNION ALL
SELECT 'JOURNEY_PHILOSOPHY', COUNT(*) FROM journey_philosophy
UNION ALL
SELECT 'POSTS', COUNT(*) FROM posts
UNION ALL
SELECT 'SETTINGS', COUNT(*) FROM settings
ORDER BY tabla;
